<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>blog – Jillian Baker - Data Science Portfolio</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-f245066ca199b7326ac6b360085ddf3a.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Jillian Baker - Data Science Portfolio</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./about.html"> 
<span class="menu-text">About Me</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="./blog.html" aria-current="page"> 
<span class="menu-text">Blog Post</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-projects" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Projects</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-projects">    
        <li>
    <a class="dropdown-item" href="./projects/index.html">
 <span class="dropdown-text">All Projects</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li>
    <a class="dropdown-item" href="./projects/eda.html">
 <span class="dropdown-text">Exploratory Data Analysis</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./projects/data-acquisition.html">
 <span class="dropdown-text">Data Acquisition</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./projects/final-project.html">
 <span class="dropdown-text">Final Project</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/jilliangbaker97"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/jillian-baker-48093b284/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#from-raw-csv-to-clean-dataset-in-10-steps-a-reproducible-data-cleaning-workflow-in-python" id="toc-from-raw-csv-to-clean-dataset-in-10-steps-a-reproducible-data-cleaning-workflow-in-python" class="nav-link active" data-scroll-target="#from-raw-csv-to-clean-dataset-in-10-steps-a-reproducible-data-cleaning-workflow-in-python">From Raw CSV to Clean Dataset in 10 Steps: A Reproducible Data Cleaning Workflow in Python</a>
  <ul class="collapse">
  <li><a href="#the-10-step-workflow" id="toc-the-10-step-workflow" class="nav-link" data-scroll-target="#the-10-step-workflow">The 10-Step Workflow</a>
  <ul class="collapse">
  <li><a href="#step-1-import-libraries" id="toc-step-1-import-libraries" class="nav-link" data-scroll-target="#step-1-import-libraries">Step 1: Import Libraries</a></li>
  <li><a href="#step-2-load-the-data" id="toc-step-2-load-the-data" class="nav-link" data-scroll-target="#step-2-load-the-data">Step 2: Load the Data</a></li>
  <li><a href="#step-3-inspect-the-dataset" id="toc-step-3-inspect-the-dataset" class="nav-link" data-scroll-target="#step-3-inspect-the-dataset">Step 3: Inspect the Dataset</a></li>
  <li><a href="#step-4-standardize-column-names" id="toc-step-4-standardize-column-names" class="nav-link" data-scroll-target="#step-4-standardize-column-names">Step 4: Standardize Column Names</a></li>
  <li><a href="#step-5-handle-missing-values" id="toc-step-5-handle-missing-values" class="nav-link" data-scroll-target="#step-5-handle-missing-values">Step 5: Handle Missing Values</a></li>
  <li><a href="#step-6-fix-data-types" id="toc-step-6-fix-data-types" class="nav-link" data-scroll-target="#step-6-fix-data-types">Step 6: Fix Data Types</a></li>
  <li><a href="#step-7-remove-duplicates" id="toc-step-7-remove-duplicates" class="nav-link" data-scroll-target="#step-7-remove-duplicates">Step 7: Remove Duplicates</a></li>
  <li><a href="#step-8-filter-or-subset-data" id="toc-step-8-filter-or-subset-data" class="nav-link" data-scroll-target="#step-8-filter-or-subset-data">Step 8: Filter or Subset Data</a></li>
  <li><a href="#step-9-create-derived-variables" id="toc-step-9-create-derived-variables" class="nav-link" data-scroll-target="#step-9-create-derived-variables">Step 9: Create Derived Variables</a></li>
  <li><a href="#step-10-save-the-clean-dataset" id="toc-step-10-save-the-clean-dataset" class="nav-link" data-scroll-target="#step-10-save-the-clean-dataset">Step 10: Save the Clean Dataset</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"><h1 class="title display-7"></h1></header><div class="quarto-title-block"><div class="quarto-title-tools-only"><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>




<section id="from-raw-csv-to-clean-dataset-in-10-steps-a-reproducible-data-cleaning-workflow-in-python" class="level1">
<h1>From Raw CSV to Clean Dataset in 10 Steps: A Reproducible Data Cleaning Workflow in Python</h1>
<p>Raw datasets are almost never analysis-ready. Column names are inconsistent, data types are incorrect, missing values appear without explanation, and duplicates quietly distort results. At first glance, a CSV file may look usable—but once you begin exploring it, small issues quickly compound into larger problems. If these issues go unchecked, exploratory data analysis (EDA) can become misleading, and any models built on top of the data may produce unreliable conclusions.</p>
<p>In real-world settings, data rarely comes clean. In fact, it is commonly said that data scientists spend <strong>60–80% of their time cleaning and preparing data</strong> rather than building models. While modeling and visualization often receive the most attention, high-quality analysis depends on well-structured, trustworthy data.</p>
<p>This is where a structured workflow becomes essential. Instead of cleaning data randomly or reactively, following a consistent step-by-step process improves clarity, reproducibility, and precision. A defined workflow helps prevent simple mistakes—such as overwriting raw files or misinterpreting data types—and creates a solid foundation for everything that follows. In this post, I’ll walk through a practical 10-step process for transforming a raw CSV file into a clean, analysis-ready dataset.</p>
<hr>
<section id="the-10-step-workflow" class="level2">
<h2 class="anchored" data-anchor-id="the-10-step-workflow">The 10-Step Workflow</h2>
<section id="step-1-import-libraries" class="level3">
<h3 class="anchored" data-anchor-id="step-1-import-libraries">Step 1: Import Libraries</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Reproducible research—where data, code, and methods are documented so that the same analysis can be re-run later—is a foundational concept in scientific data work. It promotes transparency and ensures that results can be verified, audited, or extended by others. Just as importantly, reproducibility benefits your future self. When every transformation and decision is clearly recorded, you can retrace your steps months later without relying on memory or guesswork. This significantly reduces errors caused by undocumented changes or inconsistent processes. Consistency plays a major role in making reproducibility practical. By following the same structured cleaning workflow for each dataset, you reduce the time spent deciding what to do next and increase the time spent understanding the data itself. Repeating a clear process builds familiarity and confidence, allowing you to identify issues more quickly. It also prevents scrambling when a dataset feels overwhelming or unfamiliar. Instead of reacting randomly to messy data, you move through a deliberate sequence of steps—turning chaos into a manageable, repeatable system.</p>
</section>
<section id="step-2-load-the-data" class="level3">
<h3 class="anchored" data-anchor-id="step-2-load-the-data">Step 2: Load the Data</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">"data/raw_data.csv"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Keeping raw data untouched is essential in any data workflow. If something goes wrong during cleaning—or if you later decide to approach the analysis differently—you need the ability to restart from the original source. Overwriting or modifying raw files removes that safety net. It is especially risky to delete values simply because they seem unusual or unclear. For example, what appears to be an “unknown” or outlier value may actually contain meaningful information. Removing or altering it too early can limit your understanding of the dataset and potentially bias your analysis. Preserving the raw data ensures that all original inputs remain available for review. This allows you to revisit assumptions, test alternative cleaning strategies, or reuse the dataset for a different project with new research questions. A best practice is to treat raw data as read-only and perform all cleaning and transformations on a separate copy. That way, your workflow remains both flexible and reproducible.</p>
</section>
<section id="step-3-inspect-the-dataset" class="level3">
<h3 class="anchored" data-anchor-id="step-3-inspect-the-dataset">Step 3: Inspect the Dataset</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>df.head()</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>df.info()</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>df.describe()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Carefully inspecting a dataset prevents downstream errors by revealing its current structure and potential inconsistencies. Reviewing column names, data types, and summary statistics helps identify issues early, such as mislabeled variables or unexpected missing values. It also highlights whether the data needs to be reshaped—through melting, pivoting, or aggregation—before analysis can proceed. By thoroughly examining the dataset upfront, you reduce the risk of mistakes later in the workflow and ensure a more reliable and efficient cleaning process.</p>
<p>Step 4: Standardize Column Names</p>
</section>
<section id="step-4-standardize-column-names" class="level3">
<h3 class="anchored" data-anchor-id="step-4-standardize-column-names">Step 4: Standardize Column Names</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>df.columns <span class="op">=</span> df.columns.<span class="bu">str</span>.strip().<span class="bu">str</span>.lower().<span class="bu">str</span>.replace(<span class="st">" "</span>, <span class="st">"_"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Clean naming conventions typically use lowercase letters with underscores in place of spaces (often called snake_case). This format improves readability and keeps column names consistent across datasets and projects. Spaces in column names can create subtle issues, especially when referencing variables in code. For example, column names with whitespace may require bracket notation instead of dot notation, which can interrupt workflow and increase the chance of small syntax errors. Maintaining consistent naming conventions across all datasets supports reproducibility. When column names follow predictable patterns, you can reuse code more easily without constantly renaming variables or adjusting scripts. Over time, this consistency reduces friction in your workflow and allows you to focus on analysis rather than formatting issues. Clean, standardized naming may seem like a small detail, but it plays a significant role in creating efficient and reliable data processes.</p>
</section>
<section id="step-5-handle-missing-values" class="level3">
<h3 class="anchored" data-anchor-id="step-5-handle-missing-values">Step 5: Handle Missing Values</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>df.isnull().<span class="bu">sum</span>()</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.dropna()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>The dropna() function removes rows or columns that contain missing (NA) values. By default, it drops any row with at least one missing value, though this behavior can be adjusted with parameters. While this can simplify a dataset quickly, it should be used with caution. Automatically removing rows may discard meaningful observations, especially if the missingness is limited to a single variable that is not central to your analysis. Before using dropna(), it is important to consider whether complete cases are truly required. In some analyses, every column must contain a value for the observation to be usable. In other situations, however, a row with one missing entry may still provide valuable information. Removing it could reduce sample size or introduce bias if the missing data follows a pattern. A better practice is to first assess the extent and structure of missing values. From there, you can decide whether to drop observations, impute values, or leave them as-is depending on your analytical goals. Thoughtful handling of missing data leads to more reliable and transparent results.</p>
</section>
<section id="step-6-fix-data-types" class="level3">
<h3 class="anchored" data-anchor-id="step-6-fix-data-types">Step 6: Fix Data Types</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"date"</span>] <span class="op">=</span> pd.to_datetime(df[<span class="st">"date"</span>])</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"price"</span>] <span class="op">=</span> df[<span class="st">"price"</span>].astype(<span class="bu">float</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="step-7-remove-duplicates" class="level3">
<h3 class="anchored" data-anchor-id="step-7-remove-duplicates">Step 7: Remove Duplicates</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.drop_duplicates()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="step-8-filter-or-subset-data" class="level3">
<h3 class="anchored" data-anchor-id="step-8-filter-or-subset-data">Step 8: Filter or Subset Data</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df[df[<span class="st">"price"</span>] <span class="op">&gt;</span> <span class="dv">0</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Applying logical constraints ensures that your dataset reflects realistic and meaningful values. Constraints involve filtering out observations that violate known rules of the problem—for example, negative prices, impossible dates, or ages greater than 120. These values may result from data entry errors, formatting issues, or incorrect merges. If left unchecked, they can distort summary statistics, mislead visualizations, and negatively impact model performance. By enforcing logical boundaries based on domain knowledge, you improve data quality and ensure that your analysis is grounded in plausible, interpretable observations rather than errors.</p>
</section>
<section id="step-9-create-derived-variables" class="level3">
<h3 class="anchored" data-anchor-id="step-9-create-derived-variables">Step 9: Create Derived Variables</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"revenue"</span>] <span class="op">=</span> df[<span class="st">"price"</span>] <span class="op">*</span> df[<span class="st">"quantity"</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Feature engineering often begins during the cleaning stage because this is when raw variables are transformed into more meaningful and usable forms. As you standardize types, handle missing values, and apply logical constraints, you naturally identify opportunities to create new variables—such as calculating revenue from price and quantity, extracting month or year from a date column, or generating indicator variables from categories. These derived features can better capture underlying patterns in the data and improve model performance. Rather than viewing cleaning and feature engineering as separate steps, it is more accurate to see cleaning as the foundation where thoughtful variable construction first takes shape.</p>
</section>
<section id="step-10-save-the-clean-dataset" class="level3">
<h3 class="anchored" data-anchor-id="step-10-save-the-clean-dataset">Step 10: Save the Clean Dataset</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>df.to_csv(<span class="st">"data/clean_data.csv"</span>, index<span class="op">=</span><span class="va">False</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Saving the cleaned dataset as a new file is a crucial final step in maintaining a reproducible workflow. Instead of overwriting the original raw data, export the processed version to a separate location (for example, a processed or cleanfolder) using df.to_csv(“data/clean_data.csv”, index=False). Keeping raw and cleaned data separate preserves the integrity of the original source and ensures you can restart the process if needed. Separating stages of data—raw, intermediate, and cleaned—also makes your project easier to audit, debug, and extend, reinforcing a clear and organized analytical pipeline.</p>
<p>Data cleaning is not just preparation—it is the foundation of reliable analysis. By following this structured 10-step workflow, you transform messy CSV files into trustworthy datasets ready for exploration and modeling. Try applying this workflow to your next project and notice how much smoother your analysis becomes.</p>


<!-- -->

</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb11" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># From Raw CSV to Clean Dataset in 10 Steps: A Reproducible Data Cleaning Workflow in Python</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>Raw datasets are almost never analysis-ready. Column names are inconsistent, data types are incorrect, missing values appear without explanation, and duplicates quietly distort results. At first glance, a CSV file may look usable—but once you begin exploring it, small issues quickly compound into larger problems. If these issues go unchecked, exploratory data analysis (EDA) can become misleading, and any models built on top of the data may produce unreliable conclusions.</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>In real-world settings, data rarely comes clean. In fact, it is commonly said that data scientists spend **60–80% of their time cleaning and preparing data** rather than building models. While modeling and visualization often receive the most attention, high-quality analysis depends on well-structured, trustworthy data.</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>This is where a structured workflow becomes essential. Instead of cleaning data randomly or reactively, following a consistent step-by-step process improves clarity, reproducibility, and precision. A defined workflow helps prevent simple mistakes—such as overwriting raw files or misinterpreting data types—and creates a solid foundation for everything that follows. In this post, I’ll walk through a practical 10-step process for transforming a raw CSV file into a clean, analysis-ready dataset.</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a><span class="fu">## The 10-Step Workflow</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 1: Import Libraries</span></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>Reproducible research—where data, code, and methods are documented so that the same analysis can be re-run later—is a foundational concept in scientific data work. It promotes transparency and ensures that results can be verified, audited, or extended by others. Just as importantly, reproducibility benefits your future self. When every transformation and decision is clearly recorded, you can retrace your steps months later without relying on memory or guesswork. This significantly reduces errors caused by undocumented changes or inconsistent processes.</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>Consistency plays a major role in making reproducibility practical. By following the same structured cleaning workflow for each dataset, you reduce the time spent deciding what to do next and increase the time spent understanding the data itself. Repeating a clear process builds familiarity and confidence, allowing you to identify issues more quickly. It also prevents scrambling when a dataset feels overwhelming or unfamiliar. Instead of reacting randomly to messy data, you move through a deliberate sequence of steps—turning chaos into a manageable, repeatable system.</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 2: Load the Data</span></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">"data/raw_data.csv"</span>)</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a>Keeping raw data untouched is essential in any data workflow. If something goes wrong during cleaning—or if you later decide to approach the analysis differently—you need the ability to restart from the original source. Overwriting or modifying raw files removes that safety net.</span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a>It is especially risky to delete values simply because they seem unusual or unclear. For example, what appears to be an “unknown” or outlier value may actually contain meaningful information. Removing or altering it too early can limit your understanding of the dataset and potentially bias your analysis.</span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>Preserving the raw data ensures that all original inputs remain available for review. This allows you to revisit assumptions, test alternative cleaning strategies, or reuse the dataset for a different project with new research questions. A best practice is to treat raw data as read-only and perform all cleaning and transformations on a separate copy. That way, your workflow remains both flexible and reproducible.</span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 3: Inspect the Dataset</span></span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a>df.head()</span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a>df.info()</span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a>df.describe()</span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a>Carefully inspecting a dataset prevents downstream errors by revealing its current structure and potential inconsistencies. Reviewing column names, data types, and summary statistics helps identify issues early, such as mislabeled variables or unexpected missing values. It also highlights whether the data needs to be reshaped—through melting, pivoting, or aggregation—before analysis can proceed. By thoroughly examining the dataset upfront, you reduce the risk of mistakes later in the workflow and ensure a more reliable and efficient cleaning process.</span>
<span id="cb11-39"><a href="#cb11-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-40"><a href="#cb11-40" aria-hidden="true" tabindex="-1"></a>Step 4: Standardize Column Names</span>
<span id="cb11-41"><a href="#cb11-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-42"><a href="#cb11-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-43"><a href="#cb11-43" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 4: Standardize Column Names</span></span>
<span id="cb11-44"><a href="#cb11-44" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb11-45"><a href="#cb11-45" aria-hidden="true" tabindex="-1"></a>df.columns <span class="op">=</span> df.columns.<span class="bu">str</span>.strip().<span class="bu">str</span>.lower().<span class="bu">str</span>.replace(<span class="st">" "</span>, <span class="st">"_"</span>)</span>
<span id="cb11-46"><a href="#cb11-46" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb11-47"><a href="#cb11-47" aria-hidden="true" tabindex="-1"></a>Clean naming conventions typically use lowercase letters with underscores in place of spaces (often called snake_case). This format improves readability and keeps column names consistent across datasets and projects. Spaces in column names can create subtle issues, especially when referencing variables in code. For example, column names with whitespace may require bracket notation instead of dot notation, which can interrupt workflow and increase the chance of small syntax errors.</span>
<span id="cb11-48"><a href="#cb11-48" aria-hidden="true" tabindex="-1"></a>Maintaining consistent naming conventions across all datasets supports reproducibility. When column names follow predictable patterns, you can reuse code more easily without constantly renaming variables or adjusting scripts. Over time, this consistency reduces friction in your workflow and allows you to focus on analysis rather than formatting issues. Clean, standardized naming may seem like a small detail, but it plays a significant role in creating efficient and reliable data processes.</span>
<span id="cb11-49"><a href="#cb11-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-50"><a href="#cb11-50" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 5: Handle Missing Values</span></span>
<span id="cb11-51"><a href="#cb11-51" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb11-52"><a href="#cb11-52" aria-hidden="true" tabindex="-1"></a>df.isnull().<span class="bu">sum</span>()</span>
<span id="cb11-53"><a href="#cb11-53" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.dropna()</span>
<span id="cb11-54"><a href="#cb11-54" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb11-55"><a href="#cb11-55" aria-hidden="true" tabindex="-1"></a>The dropna() function removes rows or columns that contain missing (NA) values. By default, it drops any row with at least one missing value, though this behavior can be adjusted with parameters. While this can simplify a dataset quickly, it should be used with caution. Automatically removing rows may discard meaningful observations, especially if the missingness is limited to a single variable that is not central to your analysis.</span>
<span id="cb11-56"><a href="#cb11-56" aria-hidden="true" tabindex="-1"></a>Before using dropna(), it is important to consider whether complete cases are truly required. In some analyses, every column must contain a value for the observation to be usable. In other situations, however, a row with one missing entry may still provide valuable information. Removing it could reduce sample size or introduce bias if the missing data follows a pattern.</span>
<span id="cb11-57"><a href="#cb11-57" aria-hidden="true" tabindex="-1"></a>A better practice is to first assess the extent and structure of missing values. From there, you can decide whether to drop observations, impute values, or leave them as-is depending on your analytical goals. Thoughtful handling of missing data leads to more reliable and transparent results.</span>
<span id="cb11-58"><a href="#cb11-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-59"><a href="#cb11-59" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 6: Fix Data Types</span></span>
<span id="cb11-60"><a href="#cb11-60" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb11-61"><a href="#cb11-61" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"date"</span>] <span class="op">=</span> pd.to_datetime(df[<span class="st">"date"</span>])</span>
<span id="cb11-62"><a href="#cb11-62" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"price"</span>] <span class="op">=</span> df[<span class="st">"price"</span>].astype(<span class="bu">float</span>)</span>
<span id="cb11-63"><a href="#cb11-63" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb11-64"><a href="#cb11-64" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 7: Remove Duplicates</span></span>
<span id="cb11-65"><a href="#cb11-65" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb11-66"><a href="#cb11-66" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.drop_duplicates()</span>
<span id="cb11-67"><a href="#cb11-67" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb11-68"><a href="#cb11-68" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 8: Filter or Subset Data</span></span>
<span id="cb11-69"><a href="#cb11-69" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb11-70"><a href="#cb11-70" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df[df[<span class="st">"price"</span>] <span class="op">&gt;</span> <span class="dv">0</span>]</span>
<span id="cb11-71"><a href="#cb11-71" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb11-72"><a href="#cb11-72" aria-hidden="true" tabindex="-1"></a>Applying logical constraints ensures that your dataset reflects realistic and meaningful values. Constraints involve filtering out observations that violate known rules of the problem—for example, negative prices, impossible dates, or ages greater than 120. These values may result from data entry errors, formatting issues, or incorrect merges. If left unchecked, they can distort summary statistics, mislead visualizations, and negatively impact model performance. By enforcing logical boundaries based on domain knowledge, you improve data quality and ensure that your analysis is grounded in plausible, interpretable observations rather than errors.</span>
<span id="cb11-73"><a href="#cb11-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-74"><a href="#cb11-74" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 9: Create Derived Variables</span></span>
<span id="cb11-75"><a href="#cb11-75" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb11-76"><a href="#cb11-76" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"revenue"</span>] <span class="op">=</span> df[<span class="st">"price"</span>] <span class="op">*</span> df[<span class="st">"quantity"</span>]</span>
<span id="cb11-77"><a href="#cb11-77" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb11-78"><a href="#cb11-78" aria-hidden="true" tabindex="-1"></a>Feature engineering often begins during the cleaning stage because this is when raw variables are transformed into more meaningful and usable forms. As you standardize types, handle missing values, and apply logical constraints, you naturally identify opportunities to create new variables—such as calculating revenue from price and quantity, extracting month or year from a date column, or generating indicator variables from categories. These derived features can better capture underlying patterns in the data and improve model performance. Rather than viewing cleaning and feature engineering as separate steps, it is more accurate to see cleaning as the foundation where thoughtful variable construction first takes shape.</span>
<span id="cb11-79"><a href="#cb11-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-80"><a href="#cb11-80" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 10: Save the Clean Dataset</span></span>
<span id="cb11-81"><a href="#cb11-81" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb11-82"><a href="#cb11-82" aria-hidden="true" tabindex="-1"></a>df.to_csv(<span class="st">"data/clean_data.csv"</span>, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb11-83"><a href="#cb11-83" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb11-84"><a href="#cb11-84" aria-hidden="true" tabindex="-1"></a>Saving the cleaned dataset as a new file is a crucial final step in maintaining a reproducible workflow. Instead of overwriting the original raw data, export the processed version to a separate location (for example, a processed or cleanfolder) using df.to_csv("data/clean_data.csv", index=False). Keeping raw and cleaned data separate preserves the integrity of the original source and ensures you can restart the process if needed. Separating stages of data—raw, intermediate, and cleaned—also makes your project easier to audit, debug, and extend, reinforcing a clear and organized analytical pipeline.</span>
<span id="cb11-85"><a href="#cb11-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-86"><a href="#cb11-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-87"><a href="#cb11-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-88"><a href="#cb11-88" aria-hidden="true" tabindex="-1"></a>Data cleaning is not just preparation—it is the foundation of reliable analysis. By following this structured 10-step workflow, you transform messy CSV files into trustworthy datasets ready for exploration and modeling.</span>
<span id="cb11-89"><a href="#cb11-89" aria-hidden="true" tabindex="-1"></a>Try applying this workflow to your next project and notice how much smoother your analysis becomes.</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>